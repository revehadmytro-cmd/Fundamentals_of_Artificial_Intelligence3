import io
import os

from PIL import Image
import streamlit as st
import numpy as np
import cv2
import pandas as pd
import matplotlib.pyplot as plt

st.set_page_config(page_title="–°–∏—Å—Ç–µ–ºa —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ñ—ñ–≥—É—Ä", layout="wide")
st.write("# –°–∏—Å—Ç–µ–ºa —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –≥–µ–æ–º–µ—Ç—Ä–∏—á–Ω–∏—Ö —Ñ—ñ–≥—É—Ä")


class PatternRecognitionSystem:
    def __init__(self):
        self.training_data = {}
        self.class_stats = {}
        self.recommended_grid = "6x6"
        self.class_names = ["–ö–≤–∞–¥—Ä–∞—Ç", "–ö–æ–ª–æ", "–†–æ–º–±", "–¢—Ä–∏–∫—É—Ç–Ω–∏–∫"]

    def auto_detect_grid_size(self, image_shape):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏–∑–Ω–∞—á–∞—î –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–º—ñ—Ä —Å—ñ—Ç–∫–∏"""
        height, width = image_shape
        return "6x6"  # –§—ñ–∫—Å–æ–≤–∞–Ω–æ 6x6 –¥–ª—è –≤–∞—à–∏—Ö –¥–∞–Ω–∏—Ö

    def extract_features(self, image_array, grid_size=None):
        """–í–∏–¥–æ–±—É–≤–∞—î –∞–±—Å–æ–ª—é—Ç–Ω—ñ —Ç–∞ –Ω–æ—Ä–º–æ–≤–∞–Ω—ñ –≤–µ–∫—Ç–æ—Ä–∏ –æ–∑–Ω–∞–∫"""
        if grid_size is None:
            grid_size = self.auto_detect_grid_size(image_array.shape)

        rows, cols = map(int, grid_size.split('x'))
        img_height, img_width = image_array.shape

        cell_height = img_height // rows
        cell_width = img_width // cols

        absolute_vector = []

        for i in range(rows):
            for j in range(cols):
                y_start = i * cell_height
                y_end = (i + 1) * cell_height if i < rows - 1 else img_height
                x_start = j * cell_width
                x_end = (j + 1) * cell_width if j < cols - 1 else img_width

                cell = image_array[y_start:y_end, x_start:x_end]
                black_pixels = np.sum(cell == 0)
                absolute_vector.append(black_pixels)

        # –ù–æ—Ä–º—É–≤–∞–Ω–Ω—è –∑–∞ —Å—É–º–æ—é
        total_sum = sum(absolute_vector)
        if total_sum > 0:
            normalized_vector = [val / total_sum for val in absolute_vector]
        else:
            normalized_vector = [0 for _ in absolute_vector]

        return absolute_vector, normalized_vector, grid_size

    def calculate_statistics(self, class_name):
        """–†–æ–∑—Ä–∞—Ö–æ–≤—É—î —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è –∫–ª–∞—Å—É"""
        if class_name not in self.training_data or len(self.training_data[class_name]) == 0:
            return None

        vectors = [item['normalized'] for item in self.training_data[class_name]]
        vectors_array = np.array(vectors)

        stats = {
            'mean': np.mean(vectors_array, axis=0),
            'std': np.std(vectors_array, axis=0),
            'min': np.min(vectors_array, axis=0),
            'max': np.max(vectors_array, axis=0),
            'count': len(vectors),
            'vector_size': len(vectors[0])
        }

        return stats

    def classify_pattern(self, unknown_vector, method='euclidean'):
        """–ö–ª–∞—Å–∏—Ñ—ñ–∫—É—î –Ω–µ–≤—ñ–¥–æ–º–∏–π –æ–±—Ä–∞–∑"""
        if not self.training_data:
            return "–ù–µ–º–∞—î –Ω–∞–≤—á–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö", float('inf')

        best_class = None
        best_distance = float('inf')
        unknown_size = len(unknown_vector)

        for class_name in self.training_data:
            if not self.training_data[class_name]:
                continue

            compatible_vectors = []
            for item in self.training_data[class_name]:
                if len(item['normalized']) == unknown_size:
                    compatible_vectors.append(item['normalized'])

            if not compatible_vectors:
                continue

            class_mean = np.mean(compatible_vectors, axis=0)

            if method == 'euclidean':
                distance = np.linalg.norm(np.array(unknown_vector) - np.array(class_mean))
            elif method == 'manhattan':
                distance = np.sum(np.abs(np.array(unknown_vector) - np.array(class_mean)))
            elif method == 'cosine':
                dot_product = np.dot(unknown_vector, class_mean)
                norm_unknown = np.linalg.norm(unknown_vector)
                norm_class = np.linalg.norm(class_mean)
                distance = 1 - dot_product / (norm_unknown * norm_class) if norm_unknown * norm_class > 0 else 1

            if distance < best_distance:
                best_distance = distance
                best_class = class_name

        return best_class, best_distance


# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–∏—Å—Ç–µ–º–∏
if 'recognition_system' not in st.session_state:
    st.session_state.recognition_system = PatternRecognitionSystem()

system = st.session_state.recognition_system


def load_all_images_from_folder(folder_path, class_name):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –í–°–Ü –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –ø–∞–ø–∫–∏, —â–æ –≤—ñ–¥–Ω–æ—Å—è—Ç—å—Å—è –¥–æ –∫–ª–∞—Å—É"""
    if not os.path.exists(folder_path):
        st.warning(f"–ü–∞–ø–∫–∞ {folder_path} –Ω–µ —ñ—Å–Ω—É—î.")
        return 0

    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è —Ü—å–æ–≥–æ –∫–ª–∞—Å—É
    image_files = []
    for f in os.listdir(folder_path):
        if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —Ñ–∞–π–ª –Ω–∞–ª–µ–∂–∏—Ç—å –¥–æ –ø–æ—Ç–æ—á–Ω–æ–≥–æ –∫–ª–∞—Å—É
            class_keywords = {
                "–ö–≤–∞–¥—Ä–∞—Ç": ["–∫–≤–∞–¥—Ä–∞—Ç", "square"],
                "–ö–æ–ª–æ": ["–∫–æ–ª–æ", "circle", "–∫—Ä—É–≥"],
                "–†–æ–º–±": ["—Ä–æ–º–±", "rhombus", "diamond"],
                "–¢—Ä–∏–∫—É—Ç–Ω–∏–∫": ["—Ç—Ä–∏–∫—É—Ç–Ω–∏–∫", "triangle"]
            }

            filename_lower = f.lower()
            keywords = class_keywords.get(class_name, [class_name.lower()])

            if any(keyword in filename_lower for keyword in keywords):
                image_files.append(f)

    if not image_files:
        st.warning(f"–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è –∫–ª–∞—Å—É '{class_name}' –≤ –ø–∞–ø—Ü—ñ {folder_path}")
        return 0

    loaded_count = 0
    progress_bar = st.progress(0)
    status_text = st.empty()

    for i, filename in enumerate(image_files):
        try:
            status_text.text(f"–û–±—Ä–æ–±–∫–∞ {i + 1}/{len(image_files)}: {filename}")
            progress_bar.progress((i + 1) / len(image_files))

            image_path = os.path.join(folder_path, filename)
            pil_image = Image.open(image_path)

            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ —á–æ—Ä–Ω–æ-–±—ñ–ª–µ —Ç–∞ –±—ñ–Ω–∞—Ä–∏–∑—É—î–º–æ
            image_array = np.array(pil_image.convert('L'))
            _, binary_image = cv2.threshold(image_array, 128, 255, cv2.THRESH_BINARY)

            # –í–∏–¥—ñ–ª–µ–Ω–Ω—è –æ–∑–Ω–∞–∫
            absolute_vector, normalized_vector, grid_size = system.extract_features(binary_image)

            # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
            if class_name not in system.training_data:
                system.training_data[class_name] = []

            system.training_data[class_name].append({
                'image': pil_image,
                'absolute': absolute_vector,
                'normalized': normalized_vector,
                'grid_size': grid_size,
                'filename': filename,
                'vector_size': len(absolute_vector)
            })

            loaded_count += 1

        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ {filename}: {str(e)}")

    progress_bar.empty()
    status_text.empty()

    # –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    if loaded_count > 0:
        system.class_stats[class_name] = system.calculate_statistics(class_name)

    return loaded_count


# –û—Å–Ω–æ–≤–Ω–∏–π —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å
tab1, tab2, tab3 = st.tabs(["–ù–∞–≤—á–∞–Ω–Ω—è —Å–∏—Å—Ç–µ–º–∏", "–ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è", "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤"])

with tab1:
    st.header("–ù–∞–≤—á–∞–Ω–Ω—è —Å–∏—Å—Ç–µ–º–∏ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ñ—ñ–≥—É—Ä")

    st.info("üéØ **–°–∏—Å—Ç–µ–º–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î –í–°–Ü –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –ø–∞–ø–∫–∏ –¥–ª—è –æ–±—Ä–∞–Ω–æ–≥–æ –∫–ª–∞—Å—É**")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω—å —Ñ—ñ–≥—É—Ä")

        class_name = st.selectbox("–û–±–µ—Ä—ñ—Ç—å –∫–ª–∞—Å —Ñ—ñ–≥—É—Ä–∏:", system.class_names)

        st.write("### –ú–∞—Å–æ–≤–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è")
        st.write(f"**–°–∏—Å—Ç–µ–º–∞ –∑–Ω–∞–π–¥–µ –í–°–Ü –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è:** {class_name}")

        folder_path = st.text_input("–®–ª—è—Ö –¥–æ –ø–∞–ø–∫–∏ –∑ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º–∏:", value="./img/")

        # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –í–°–Ü–• –∑–æ–±—Ä–∞–∂–µ–Ω—å –∫–ª–∞—Å—É
        if st.button("üìÅ –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –í–°–Ü –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ü—å–æ–≥–æ –∫–ª–∞—Å—É"):
            with st.spinner(f"–ü–æ—à—É–∫ —Ç–∞ –æ–±—Ä–æ–±–∫–∞ –í–°–Ü–• –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è {class_name}..."):
                loaded_count = load_all_images_from_folder(folder_path, class_name)
                if loaded_count > 0:
                    st.success(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –í–°–Ü {loaded_count} –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è —Ñ—ñ–≥—É—Ä–∏ '{class_name}'")

                    # –ü–æ–∫–∞–∑—É—î–º–æ —Å–ø–∏—Å–æ–∫ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤
                    if class_name in system.training_data:
                        st.write("**–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ —Ñ–∞–π–ª–∏:**")
                        files_col1, files_col2 = st.columns(2)
                        files_list = [sample['filename'] for sample in system.training_data[class_name]]

                        mid_index = len(files_list) // 2
                        with files_col1:
                            for filename in files_list[:mid_index]:
                                st.write(f"‚Ä¢ {filename}")
                        with files_col2:
                            for filename in files_list[mid_index:]:
                                st.write(f"‚Ä¢ {filename}")
                else:
                    st.error(f"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è –∫–ª–∞—Å—É '{class_name}'")

        st.write("---")
        st.subheader("–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –≤—Å—ñ –∫–ª–∞—Å–∏ –æ–¥—Ä–∞–∑—É")

        if st.button("üöÄ –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –í–°–Ü –∫–ª–∞—Å–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ"):
            total_loaded = 0
            progress_text = st.empty()

            for i, cls in enumerate(system.class_names):
                progress_text.text(f"–û–±—Ä–æ–±–∫–∞ –∫–ª–∞—Å—É {i + 1}/{len(system.class_names)}: {cls}")
                loaded_count = load_all_images_from_folder("./img/", cls)
                total_loaded += loaded_count
                if loaded_count > 0:
                    st.success(f"‚úÖ {cls}: {loaded_count} –∑–æ–±—Ä–∞–∂–µ–Ω—å")
                else:
                    st.warning(f"‚ö†Ô∏è {cls}: –∑–æ–±—Ä–∞–∂–µ–Ω—å –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")

            progress_text.empty()

            if total_loaded > 0:
                st.success(f"üéâ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –≤—Å—å–æ–≥–æ: {total_loaded} –∑–æ–±—Ä–∞–∂–µ–Ω—å")
            else:
                st.error("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∂–æ–¥–Ω–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è")

    with col2:
        st.subheader("–ü–æ—Ç–æ—á–Ω–∞ –Ω–∞–≤—á–∞–ª—å–Ω–∞ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å")

        total_samples = 0
        for class_name in system.class_names:
            if class_name in system.training_data and system.training_data[class_name]:
                samples = system.training_data[class_name]
                vector_size = samples[0]['vector_size']
                grid_size = samples[0]['grid_size']

                st.write(f"### {class_name}")
                st.write(f"**–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑—Ä–∞–∑–∫—ñ–≤:** {len(samples)}")
                st.write(f"**–†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä—ñ–≤:** {vector_size} –æ–∑–Ω–∞–∫")
                st.write(f"**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∞ —Å—ñ—Ç–∫–∞:** {grid_size}")

                # –ü–æ–∫–∞–∑—É—î–º–æ –≤—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∫–ª–∞—Å—É –≤ —Å—ñ—Ç—Ü—ñ
                st.write("**–£—Å—ñ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è:**")
                num_cols = 4  # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Å—Ç–æ–≤–ø—Ü—ñ–≤ –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è
                cols = st.columns(num_cols)

                for i, sample in enumerate(samples):
                    with cols[i % num_cols]:
                        st.image(sample['image'], width=80, caption=sample['filename'])

                # –î–µ—Ç–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –≤–µ–∫—Ç–æ—Ä–∏
                with st.expander(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ–∫—Ç–æ—Ä—ñ–≤ –¥–ª—è {class_name}"):
                    st.write("**–û—Å—Ç–∞–Ω–Ω—ñ–π –æ–±—Ä–æ–±–ª–µ–Ω–∏–π –∑—Ä–∞–∑–æ–∫:**")
                    last_sample = samples[-1]

                    col_a, col_b = st.columns(2)
                    with col_a:
                        st.write("üìà –ê–±—Å–æ–ª—é—Ç–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è:")
                        abs_text = "; ".join([f"{val}" for val in last_sample['absolute'][:8]])
                        if len(last_sample['absolute']) > 8:
                            abs_text += f"..."
                        st.text_area("", abs_text, height=60, key=f"abs_{class_name}")

                    with col_b:
                        st.write("üìä –ù–æ—Ä–º–æ–≤–∞–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è:")
                        norm_text = "; ".join([f"{val:.4f}" for val in last_sample['normalized'][:8]])
                        if len(last_sample['normalized']) > 8:
                            norm_text += f"..."
                        st.text_area("", norm_text, height=60, key=f"norm_{class_name}")

                    # –ó–∞–≥–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—É
                    if class_name in system.class_stats and system.class_stats[class_name]:
                        stats = system.class_stats[class_name]
                        st.write(f"**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–ª–∞—Å—É:**")
                        st.write(f"- –°–µ—Ä–µ–¥–Ω—î –∑–Ω–∞—á–µ–Ω–Ω—è –æ–∑–Ω–∞–∫: {np.mean(stats['mean']):.4f}")
                        st.write(f"- –°–µ—Ä–µ–¥–Ω—î –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è: {np.mean(stats['std']):.4f}")

                total_samples += len(samples)
                st.write("---")
            else:
                st.write(f"### {class_name}")
                st.write("**–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑—Ä–∞–∑–∫—ñ–≤:** 0")
                st.write("---")

        # –ó–∞–≥–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        st.subheader("üìà –ó–∞–≥–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        st.write(f"**–í—Å—å–æ–≥–æ –∑—Ä–∞–∑–∫—ñ–≤ —É —Å–∏—Å—Ç–µ–º—ñ:** {total_samples}")
        st.write(
            f"**–ù–∞–≤—á–µ–Ω—ñ –∫–ª–∞—Å–∏:** {sum(1 for cls in system.class_names if cls in system.training_data and system.training_data[cls])}/{len(system.class_names)}")

with tab2:
    st.header("–ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è –Ω–µ–≤—ñ–¥–æ–º–æ—ó —Ñ—ñ–≥—É—Ä–∏")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("–í–≤–µ–¥–µ–Ω–Ω—è —Ñ—ñ–≥—É—Ä–∏ –¥–ª—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è")

        classification_method = st.selectbox("–ú–µ—Ç–æ–¥ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó:",
                                             ["euclidean", "manhattan", "cosine"])

        unknown_file = st.file_uploader("–û–±–µ—Ä—ñ—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ñ—ñ–≥—É—Ä–∏",
                                        type=["bmp", "png", ".jpg", ".jpeg"])

        if unknown_file and st.button("üîç –†–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ —Ñ—ñ–≥—É—Ä—É"):
            try:
                # –û–±—Ä–æ–±–∫–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
                image_bytes = unknown_file.read()
                pil_image = Image.open(io.BytesIO(image_bytes))
                image_array = np.array(pil_image.convert('L'))
                _, binary_image = cv2.threshold(image_array, 128, 255, cv2.THRESH_BINARY)

                # –í–∏–¥—ñ–ª–µ–Ω–Ω—è –æ–∑–Ω–∞–∫
                absolute_vector, normalized_vector, detected_grid = system.extract_features(binary_image)

                # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
                st.image(pil_image, caption=f"–¢–µ—Å—Ç–æ–≤–∞ —Ñ—ñ–≥—É—Ä–∞: {unknown_file.name}", use_column_width=True)

                st.write("### –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∞–Ω–∞–ª—ñ–∑—É:")
                st.write(f"**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∞ —Å—ñ—Ç–∫–∞:** {detected_grid}")
                st.write(f"**–†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–∞:** {len(absolute_vector)} –æ–∑–Ω–∞–∫")

                # –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è
                if system.training_data:
                    result_class, distance = system.classify_pattern(normalized_vector, classification_method)

                    if result_class:
                        confidence = max(0, 1 - distance) * 100

                        # –†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
                        st.success(f"**–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è:** {result_class}")

                        # –ú–µ—Ç—Ä–∏–∫–∏
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("–í—ñ–¥—Å—Ç–∞–Ω—å", f"{distance:.6f}")
                        with col2:
                            st.metric("–í–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å", f"{confidence:.1f}%")
                        with col3:
                            st.metric("–ú–µ—Ç–æ–¥", classification_method)


                        st.write("**–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑:**")
                        analysis_data = []
                        for class_name in system.class_names:
                            if class_name in system.training_data:
                                compatible_samples = [item for item in system.training_data[class_name]
                                                      if len(item['normalized']) == len(normalized_vector)]
                                analysis_data.append({
                                    '–ö–ª–∞—Å': class_name,
                                    '–ó—Ä–∞–∑–∫—ñ–≤': len(system.training_data[class_name]),
                                    '–°—É–º—ñ—Å–Ω–∏—Ö': len(compatible_samples),
                                    '–í—ñ–¥—Å—Ç–∞–Ω—å': distance if class_name == result_class else "N/A"
                                })

                        if analysis_data:
                            df = pd.DataFrame(analysis_data)
                            st.dataframe(df, hide_index=True)

                    else:
                        st.error("–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —Å—É–º—ñ—Å–Ω–∏—Ö –Ω–∞–≤—á–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö")

                else:
                    st.error("–°–∏—Å—Ç–µ–º–∞ —â–µ –Ω–µ –Ω–∞–≤—á–µ–Ω–∞")

            except Exception as e:
                st.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏: {str(e)}")

    with col2:
        st.subheader("–°—Ç–∞–Ω —Å–∏—Å—Ç–µ–º–∏")

        if system.training_data:
            st.success("‚úÖ –°–∏—Å—Ç–µ–º–∞ –Ω–∞–≤—á–µ–Ω–∞")

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞–≤—á–µ–Ω–∏—Ö –∫–ª–∞—Å—ñ–≤
            st.write("**–ù–∞–≤—á–µ–Ω—ñ –∫–ª–∞—Å–∏:**")
            for class_name in system.class_names:
                if class_name in system.training_data:
                    count = len(system.training_data[class_name])
                    st.write(f"‚úÖ **{class_name}:** {count} –∑—Ä–∞–∑–∫—ñ–≤")
                else:
                    st.write(f"‚ùå **{class_name}:** –Ω–µ –Ω–∞–≤—á–µ–Ω–∏–π")

            # –ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è
            total_samples = sum(len(system.training_data[cls]) for cls in system.training_data)
            st.write(f"**–í—Å—å–æ–≥–æ –Ω–∞–≤—á–∞–ª—å–Ω–∏—Ö –∑—Ä–∞–∑–∫—ñ–≤:** {total_samples}")

        else:
            st.warning("‚ö†Ô∏è –°–∏—Å—Ç–µ–º–∞ –Ω–µ –Ω–∞–≤—á–µ–Ω–∞")

with tab3:
    st.header("–°—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ —Ñ—ñ–≥—É—Ä")

    if system.class_stats:
        for class_name in system.class_names:
            if class_name in system.class_stats and system.class_stats[class_name]:
                stats = system.class_stats[class_name]

                st.subheader(f"üìä {class_name}")

                # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω—ñ –∫–∞—Ä—Ç–∫–∏
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("–ó—Ä–∞–∑–∫—ñ–≤", stats['count'])
                with col2:
                    st.metric("–û–∑–Ω–∞–∫", stats['vector_size'])
                with col3:
                    avg_mean = np.mean(stats['mean'])
                    st.metric("–°–µ—Ä–µ–¥–Ω—î", f"{avg_mean:.4f}")
                with col4:
                    avg_std = np.mean(stats['std'])
                    st.metric("–í—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è", f"{avg_std:.4f}")

                # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
                fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))

                ax1.bar(range(stats['vector_size']), stats['mean'], alpha=0.7, color='blue')
                ax1.set_title(f'–°–µ—Ä–µ–¥–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –æ–∑–Ω–∞–∫ - {class_name}')
                ax1.set_xlabel('–ù–æ–º–µ—Ä –æ–∑–Ω–∞–∫–∏')
                ax1.set_ylabel('–ó–Ω–∞—á–µ–Ω–Ω—è')
                ax1.grid(True, alpha=0.3)

                ax2.bar(range(stats['vector_size']), stats['std'], alpha=0.7, color='red')
                ax2.set_title(f'–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ñ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è - {class_name}')
                ax2.set_xlabel('–ù–æ–º–µ—Ä –æ–∑–Ω–∞–∫–∏')
                ax2.set_ylabel('–í—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è')
                ax2.grid(True, alpha=0.3)

                plt.tight_layout()
                st.pyplot(fig)

                st.write("---")
    else:
        st.info("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑'—è–≤–∏—Ç—å—Å—è –ø—ñ—Å–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è —Å–∏—Å—Ç–µ–º–∏")

# –ë—ñ—á–Ω–∞ –ø–∞–Ω–µ–ª—å
st.sidebar.header("‚öôÔ∏è –ö–µ—Ä—É–≤–∞–Ω–Ω—è —Å–∏—Å—Ç–µ–º–æ—é")

if st.sidebar.button("üîÑ –û—á–∏—Å—Ç–∏—Ç–∏ –≤—Å—ñ –¥–∞–Ω—ñ"):
    st.session_state.recognition_system = PatternRecognitionSystem()
    st.rerun()